{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import timeit\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "from text_utils import TextLoader\n",
    "from text_utils import batch_generator\n",
    "from tensorflow.contrib import rnn\n",
    "from char_rnn_model import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define directories, hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = ''\n",
    "batch_size = 32\n",
    "seq_len = 50 \n",
    "max_steps = 20000\n",
    "model_path = 'char_rnn'\n",
    "save_every_n = 1000\n",
    "log_every_n = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data using TextLoader object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = TextLoader(directory, batch_size, seq_len)\n",
    "train_set, val_set, char = load.loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n",
      "3745213\n",
      "66\n"
     ]
    }
   ],
   "source": [
    "print(len(char))\n",
    "print(len(train_set))\n",
    "print(load.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"cedjkw fer.iorfe rf\\nf refrioec\"\n",
    "b = list(string)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 100/20000...  loss: 3.2599...  0.0972 sec/batch\n",
      "step: 200/20000...  loss: 3.2429...  0.1032 sec/batch\n",
      "step: 300/20000...  loss: 3.0581...  0.0919 sec/batch\n",
      "step: 400/20000...  loss: 2.8773...  0.0979 sec/batch\n",
      "step: 500/20000...  loss: 2.8133...  0.0999 sec/batch\n",
      "step: 600/20000...  loss: 2.8124...  0.1006 sec/batch\n",
      "step: 700/20000...  loss: 2.7048...  0.0990 sec/batch\n",
      "step: 800/20000...  loss: 2.6852...  0.1020 sec/batch\n",
      "step: 900/20000...  loss: 2.6699...  0.0963 sec/batch\n",
      "step: 1000/20000...  loss: 2.6179...  0.0996 sec/batch\n",
      "step: 1100/20000...  loss: 2.6086...  0.0973 sec/batch\n",
      "step: 1200/20000...  loss: 2.6421...  0.0947 sec/batch\n",
      "step: 1300/20000...  loss: 2.6350...  0.1031 sec/batch\n",
      "step: 1400/20000...  loss: 2.5304...  0.0991 sec/batch\n",
      "step: 1500/20000...  loss: 2.5393...  0.0970 sec/batch\n",
      "step: 1600/20000...  loss: 2.5526...  0.1022 sec/batch\n",
      "step: 1700/20000...  loss: 2.5524...  0.0953 sec/batch\n",
      "step: 1800/20000...  loss: 2.5507...  0.0998 sec/batch\n",
      "step: 1900/20000...  loss: 2.5168...  0.0983 sec/batch\n",
      "step: 2000/20000...  loss: 2.5101...  0.1008 sec/batch\n",
      "step: 2100/20000...  loss: 2.5342...  0.0988 sec/batch\n",
      "step: 2200/20000...  loss: 2.4738...  0.0967 sec/batch\n",
      "step: 2300/20000...  loss: 2.4890...  0.1014 sec/batch\n",
      "step: 2400/20000...  loss: 2.4174...  0.0983 sec/batch\n",
      "step: 2500/20000...  loss: 2.4604...  0.0966 sec/batch\n",
      "step: 2600/20000...  loss: 2.4306...  0.1021 sec/batch\n",
      "step: 2700/20000...  loss: 2.4172...  0.0979 sec/batch\n",
      "step: 2800/20000...  loss: 2.4142...  0.0988 sec/batch\n",
      "step: 2900/20000...  loss: 2.4804...  0.1007 sec/batch\n",
      "step: 3000/20000...  loss: 2.4966...  0.0969 sec/batch\n",
      "step: 3100/20000...  loss: 2.4283...  0.0934 sec/batch\n",
      "step: 3200/20000...  loss: 2.4585...  0.0987 sec/batch\n",
      "step: 3300/20000...  loss: 2.4378...  0.0960 sec/batch\n",
      "step: 3400/20000...  loss: 2.4524...  0.0997 sec/batch\n",
      "step: 3500/20000...  loss: 2.4764...  0.1021 sec/batch\n",
      "step: 3600/20000...  loss: 2.4326...  0.0979 sec/batch\n",
      "step: 3700/20000...  loss: 2.3481...  0.1019 sec/batch\n",
      "step: 3800/20000...  loss: 2.3502...  0.1001 sec/batch\n",
      "step: 3900/20000...  loss: 2.3739...  0.1019 sec/batch\n",
      "step: 4000/20000...  loss: 2.3289...  0.0951 sec/batch\n",
      "step: 4100/20000...  loss: 2.3904...  0.1017 sec/batch\n",
      "step: 4200/20000...  loss: 2.3980...  0.0978 sec/batch\n",
      "step: 4300/20000...  loss: 2.3791...  0.1003 sec/batch\n",
      "step: 4400/20000...  loss: 2.3920...  0.0966 sec/batch\n",
      "step: 4500/20000...  loss: 2.3729...  0.0992 sec/batch\n",
      "step: 4600/20000...  loss: 2.3246...  0.0995 sec/batch\n",
      "step: 4700/20000...  loss: 2.3212...  0.0941 sec/batch\n",
      "step: 4800/20000...  loss: 2.3334...  0.0988 sec/batch\n",
      "step: 4900/20000...  loss: 2.3608...  0.0956 sec/batch\n",
      "step: 5000/20000...  loss: 2.3128...  0.1028 sec/batch\n",
      "step: 5100/20000...  loss: 2.3176...  0.1018 sec/batch\n",
      "step: 5200/20000...  loss: 2.3485...  0.0976 sec/batch\n",
      "step: 5300/20000...  loss: 2.3868...  0.0989 sec/batch\n",
      "step: 5400/20000...  loss: 2.4080...  0.0973 sec/batch\n",
      "step: 5500/20000...  loss: 2.3592...  0.1000 sec/batch\n",
      "step: 5600/20000...  loss: 2.3850...  0.0976 sec/batch\n",
      "step: 5700/20000...  loss: 2.2506...  0.0944 sec/batch\n",
      "step: 5800/20000...  loss: 2.2962...  0.1031 sec/batch\n",
      "step: 5900/20000...  loss: 2.3048...  0.0966 sec/batch\n",
      "step: 6000/20000...  loss: 2.3003...  0.1004 sec/batch\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "step: 6100/20000...  loss: 2.3554...  0.0964 sec/batch\n",
      "step: 6200/20000...  loss: 2.2850...  0.0980 sec/batch\n",
      "step: 6300/20000...  loss: 2.3457...  0.0972 sec/batch\n",
      "step: 6400/20000...  loss: 2.3464...  0.0942 sec/batch\n",
      "step: 6500/20000...  loss: 2.3191...  0.0942 sec/batch\n",
      "step: 6600/20000...  loss: 2.3278...  0.0990 sec/batch\n",
      "step: 6700/20000...  loss: 2.2906...  0.0920 sec/batch\n",
      "step: 6800/20000...  loss: 2.2710...  0.1014 sec/batch\n",
      "step: 6900/20000...  loss: 2.3082...  0.0972 sec/batch\n",
      "step: 7000/20000...  loss: 2.3645...  0.0951 sec/batch\n",
      "step: 7100/20000...  loss: 2.2598...  0.0998 sec/batch\n",
      "step: 7200/20000...  loss: 2.3358...  0.0928 sec/batch\n",
      "step: 7300/20000...  loss: 2.3318...  0.0991 sec/batch\n",
      "step: 7400/20000...  loss: 2.3162...  0.1013 sec/batch\n",
      "step: 7500/20000...  loss: 2.2528...  0.1024 sec/batch\n",
      "step: 7600/20000...  loss: 2.2397...  0.1006 sec/batch\n",
      "step: 7700/20000...  loss: 2.3293...  0.1055 sec/batch\n",
      "step: 7800/20000...  loss: 2.2494...  0.1009 sec/batch\n",
      "step: 7900/20000...  loss: 2.2934...  0.0978 sec/batch\n",
      "step: 8000/20000...  loss: 2.1818...  0.0972 sec/batch\n",
      "step: 8100/20000...  loss: 2.2659...  0.1012 sec/batch\n",
      "step: 8200/20000...  loss: 2.2747...  0.0963 sec/batch\n",
      "step: 8300/20000...  loss: 2.2198...  0.0995 sec/batch\n",
      "step: 8400/20000...  loss: 2.2424...  0.0975 sec/batch\n",
      "step: 8500/20000...  loss: 2.2073...  0.1019 sec/batch\n",
      "step: 8600/20000...  loss: 2.1791...  0.1005 sec/batch\n",
      "step: 8700/20000...  loss: 2.2785...  0.1057 sec/batch\n",
      "step: 8800/20000...  loss: 2.3130...  0.0968 sec/batch\n",
      "step: 8900/20000...  loss: 2.2303...  0.0991 sec/batch\n",
      "step: 9000/20000...  loss: 2.2360...  0.0981 sec/batch\n",
      "step: 9100/20000...  loss: 2.2393...  0.0975 sec/batch\n",
      "step: 9200/20000...  loss: 2.2259...  0.0958 sec/batch\n",
      "step: 9300/20000...  loss: 2.2712...  0.0953 sec/batch\n",
      "step: 9400/20000...  loss: 2.2860...  0.1008 sec/batch\n",
      "step: 9500/20000...  loss: 2.2409...  0.0954 sec/batch\n",
      "step: 9600/20000...  loss: 2.2004...  0.0984 sec/batch\n",
      "step: 9700/20000...  loss: 2.2550...  0.0987 sec/batch\n",
      "step: 9800/20000...  loss: 2.2696...  0.1009 sec/batch\n",
      "step: 9900/20000...  loss: 2.2726...  0.0986 sec/batch\n",
      "step: 10000/20000...  loss: 2.1855...  0.0936 sec/batch\n",
      "step: 10100/20000...  loss: 2.2353...  0.1019 sec/batch\n",
      "step: 10200/20000...  loss: 2.3159...  0.1011 sec/batch\n",
      "step: 10300/20000...  loss: 2.2468...  0.1027 sec/batch\n",
      "step: 10400/20000...  loss: 2.2617...  0.0973 sec/batch\n",
      "step: 10500/20000...  loss: 2.2922...  0.0948 sec/batch\n",
      "step: 10600/20000...  loss: 2.2744...  0.0948 sec/batch\n",
      "step: 10700/20000...  loss: 2.2694...  0.1002 sec/batch\n",
      "step: 10800/20000...  loss: 2.2668...  0.0956 sec/batch\n",
      "step: 10900/20000...  loss: 2.1600...  0.0941 sec/batch\n",
      "step: 11000/20000...  loss: 2.2773...  0.0953 sec/batch\n",
      "step: 11100/20000...  loss: 2.2102...  0.1017 sec/batch\n",
      "step: 11200/20000...  loss: 2.2853...  0.1009 sec/batch\n",
      "step: 11300/20000...  loss: 2.1794...  0.0943 sec/batch\n",
      "step: 11400/20000...  loss: 2.1902...  0.0980 sec/batch\n",
      "step: 11500/20000...  loss: 2.1867...  0.0937 sec/batch\n",
      "step: 11600/20000...  loss: 2.2563...  0.0982 sec/batch\n",
      "step: 11700/20000...  loss: 2.1664...  0.0975 sec/batch\n",
      "step: 11800/20000...  loss: 2.1684...  0.0958 sec/batch\n",
      "step: 11900/20000...  loss: 2.1712...  0.0995 sec/batch\n",
      "step: 12000/20000...  loss: 2.1108...  0.0974 sec/batch\n",
      "step: 12100/20000...  loss: 2.1879...  0.1012 sec/batch\n",
      "step: 12200/20000...  loss: 2.1613...  0.1003 sec/batch\n",
      "step: 12300/20000...  loss: 2.2225...  0.0954 sec/batch\n",
      "step: 12400/20000...  loss: 2.2253...  0.0972 sec/batch\n",
      "step: 12500/20000...  loss: 2.1875...  0.0995 sec/batch\n",
      "step: 12600/20000...  loss: 2.2161...  0.0971 sec/batch\n",
      "step: 12700/20000...  loss: 2.2384...  0.0978 sec/batch\n",
      "step: 12800/20000...  loss: 2.2362...  0.1001 sec/batch\n",
      "step: 12900/20000...  loss: 2.2396...  0.0946 sec/batch\n",
      "step: 13000/20000...  loss: 2.3122...  0.1006 sec/batch\n",
      "step: 13100/20000...  loss: 2.1579...  0.1016 sec/batch\n",
      "step: 13200/20000...  loss: 2.1976...  0.0943 sec/batch\n",
      "step: 13300/20000...  loss: 2.2138...  0.0984 sec/batch\n",
      "step: 13400/20000...  loss: 2.2430...  0.1003 sec/batch\n",
      "step: 13500/20000...  loss: 2.2487...  0.0973 sec/batch\n",
      "step: 13600/20000...  loss: 2.2090...  0.0979 sec/batch\n",
      "step: 13700/20000...  loss: 2.1778...  0.1013 sec/batch\n",
      "step: 13800/20000...  loss: 2.2278...  0.0943 sec/batch\n",
      "step: 13900/20000...  loss: 2.1732...  0.1030 sec/batch\n",
      "step: 14000/20000...  loss: 2.1377...  0.0979 sec/batch\n",
      "step: 14100/20000...  loss: 2.1317...  0.1003 sec/batch\n",
      "step: 14200/20000...  loss: 2.1101...  0.0944 sec/batch\n",
      "step: 14300/20000...  loss: 2.1771...  0.0999 sec/batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 14400/20000...  loss: 2.1469...  0.0985 sec/batch\n",
      "step: 14500/20000...  loss: 2.1394...  0.1022 sec/batch\n",
      "step: 14600/20000...  loss: 2.1966...  0.1003 sec/batch\n",
      "step: 14700/20000...  loss: 2.2354...  0.0948 sec/batch\n",
      "step: 14800/20000...  loss: 2.1603...  0.0956 sec/batch\n",
      "step: 14900/20000...  loss: 2.2208...  0.0994 sec/batch\n",
      "step: 15000/20000...  loss: 2.2139...  0.0969 sec/batch\n",
      "step: 15100/20000...  loss: 2.2278...  0.0979 sec/batch\n",
      "step: 15200/20000...  loss: 2.2422...  0.1022 sec/batch\n",
      "step: 15300/20000...  loss: 2.2100...  0.1019 sec/batch\n",
      "step: 15400/20000...  loss: 2.1558...  0.0992 sec/batch\n",
      "step: 15500/20000...  loss: 2.0725...  0.1015 sec/batch\n",
      "step: 15600/20000...  loss: 2.1873...  0.1024 sec/batch\n",
      "step: 15700/20000...  loss: 2.1234...  0.1009 sec/batch\n",
      "step: 15800/20000...  loss: 2.1682...  0.0985 sec/batch\n",
      "step: 15900/20000...  loss: 2.2006...  0.1034 sec/batch\n",
      "step: 16000/20000...  loss: 2.1389...  0.0992 sec/batch\n",
      "step: 16100/20000...  loss: 2.1713...  0.0998 sec/batch\n",
      "step: 16200/20000...  loss: 2.1895...  0.1001 sec/batch\n",
      "step: 16300/20000...  loss: 2.1875...  0.1013 sec/batch\n",
      "step: 16400/20000...  loss: 2.1341...  0.0973 sec/batch\n",
      "step: 16500/20000...  loss: 2.1248...  0.0999 sec/batch\n",
      "step: 16600/20000...  loss: 2.1778...  0.0971 sec/batch\n",
      "step: 16700/20000...  loss: 2.1272...  0.0978 sec/batch\n",
      "step: 16800/20000...  loss: 2.1593...  0.0959 sec/batch\n",
      "step: 16900/20000...  loss: 2.1838...  0.0995 sec/batch\n",
      "step: 17000/20000...  loss: 2.1937...  0.1003 sec/batch\n",
      "step: 17100/20000...  loss: 2.2223...  0.0999 sec/batch\n",
      "step: 17200/20000...  loss: 2.1924...  0.0998 sec/batch\n",
      "step: 17300/20000...  loss: 2.2367...  0.0988 sec/batch\n",
      "step: 17400/20000...  loss: 2.0942...  0.0976 sec/batch\n",
      "step: 17500/20000...  loss: 2.1531...  0.1026 sec/batch\n",
      "step: 17600/20000...  loss: 2.1678...  0.0979 sec/batch\n",
      "step: 17700/20000...  loss: 2.1360...  0.0993 sec/batch\n",
      "step: 17800/20000...  loss: 2.2091...  0.1000 sec/batch\n",
      "step: 17900/20000...  loss: 2.1552...  0.1004 sec/batch\n",
      "step: 18000/20000...  loss: 2.2066...  0.0951 sec/batch\n",
      "step: 18100/20000...  loss: 2.2387...  0.0967 sec/batch\n",
      "step: 18200/20000...  loss: 2.1753...  0.0931 sec/batch\n",
      "step: 18300/20000...  loss: 2.1485...  0.0942 sec/batch\n",
      "step: 18400/20000...  loss: 2.1639...  0.1028 sec/batch\n",
      "step: 18500/20000...  loss: 2.1385...  0.1013 sec/batch\n",
      "step: 18600/20000...  loss: 2.2051...  0.1008 sec/batch\n",
      "step: 18700/20000...  loss: 2.2108...  0.0968 sec/batch\n",
      "step: 18800/20000...  loss: 2.1751...  0.0962 sec/batch\n",
      "step: 18900/20000...  loss: 2.1816...  0.0989 sec/batch\n",
      "step: 19000/20000...  loss: 2.1911...  0.1013 sec/batch\n",
      "step: 19100/20000...  loss: 2.1903...  0.0968 sec/batch\n",
      "step: 19200/20000...  loss: 2.1504...  0.1001 sec/batch\n",
      "step: 19300/20000...  loss: 2.1518...  0.0988 sec/batch\n",
      "step: 19400/20000...  loss: 2.1964...  0.0957 sec/batch\n",
      "step: 19500/20000...  loss: 2.1618...  0.1021 sec/batch\n",
      "step: 19600/20000...  loss: 2.1948...  0.0974 sec/batch\n",
      "step: 19700/20000...  loss: 2.1033...  0.0992 sec/batch\n",
      "step: 19800/20000...  loss: 2.1500...  0.0935 sec/batch\n",
      "step: 19900/20000...  loss: 2.1890...  0.0959 sec/batch\n",
      "step: 20000/20000...  loss: 2.1106...  0.0973 sec/batch\n"
     ]
    }
   ],
   "source": [
    "generator = batch_generator(train_set, batch_size, seq_len)\n",
    "model1 = Model(batch_size, seq_len, load.vocab_size)\n",
    "model1.train(generator, max_steps, model_path, save_every_n, log_every_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from char_rnn/model-20000\n",
      "Restored from: char_rnn/model-20000\n",
      "The then the palling, to why to the thangor and morthen thit.That wourd and hund too are a sent all stald thee?CALIO:And make think the man of thes this, when this sarse shall.HAMELIUS:What so tinl they, sire heaven to so therefon tinn to heart: what a pleations and all the comenter and are hear a pood,And all man and the touse thee.CALERIO:I told thou will stroth see seat, sin, how a masters with the tomen, this ale to measers the peese of hand of mine spead, thy sour and man of him; shall see the poder,And all that we to the pooneth of her of that think and hast meast.CRATENIO:I do manys hand'd so take the comand. That me take and have to me of,This thy mones and alter thought to me sonrers, would that with the prister to healter and a critter of astatter.BARSENTIO:I dil weals, and she have shall tho sear.HOMILOLK:I wall see an trome on a stolt in that the ponss will but shall talk one and as me singith. Hour to my dead of my lane.BELILAN:Woons, sear all think and hath see made to this \n"
     ]
    }
   ],
   "source": [
    "checkpoint = tf.train.latest_checkpoint('char_rnn/')\n",
    "model = Model(batch_size=1, seq_len=1, vocab_size=load.vocab_size, training=False)\n",
    "model.load(checkpoint)\n",
    "start_string = 'The'\n",
    "n = 1000\n",
    "result = model.sample(char, load.vocab, n, start_string)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'b': 0, 'J': 11, 'S': 2, 'j': 3, 'W': 4, '3': 5, 'I': 6, 'O': 8, 'M': 33, 'H': 9, 'q': 10, 'l': 51, 'k': 12, ' ': 13, 'm': 15, 'T': 16, \"'\": 58, 'A': 17, 'Q': 18, ':': 1, 'U': 21, 'X': 22, 'f': 14, '?': 23, 'p': 24, 'F': 27, 'w': 32, 'R': 28, 'D': 35, 'r': 26, 'C': 29, 'B': 31, 'o': 34, '\\n': 46, 'a': 36, 'V': 39, 'x': 54, 't': 37, 'i': 38, 'v': 52, ']': 40, 'E': 41, 'e': 42, 'n': 7, '.': 62, 'y': 43, 'P': 44, 'g': 47, '&': 55, 'd': 45, ',': 19, '!': 48, 'G': 53, 'z': 30, 'u': 50, '$': 56, '[': 57, 'L': 25, 'N': 20, 'h': 59, 'K': 60, 'Z': 61, '-': 49, 'Y': 63, ';': 64, 'c': 65, 's': 66}\n"
     ]
    }
   ],
   "source": [
    "print(load.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b', ':', 'S', 'j', 'W', '3', 'I', 'n', 'O', 'H', 'q', 'J', 'k', ' ', 'f', 'm', 'T', 'A', 'Q', ',', 'N', 'U', 'X', '?', 'p', 'L', 'r', 'F', 'R', 'C', 'z', 'B', 'w', 'M', 'o', 'D', 'a', 't', 'i', 'V', ']', 'E', 'e', 'y', 'P', 'd', '\\n', 'g', '!', '-', 'u', 'l', 'v', 'G', 'x', '&', '$', '[', \"'\", 'h', 'K', 'Z', '.', 'Y', ';', 'c', 's']\n"
     ]
    }
   ],
   "source": [
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
